paper_id,title,year,authors,venue_or_publisher,domain_bucket,platforms_named,mobile_relevant,AAF_subtype,adversary_goal,attack_target,evidence_kind,technique_summary,key_artifacts_or_signals,notes,needs_review,citation
P001,Generative Adversarial Attacks Against Deep-Learning-Based Camera Model Identification,2025,Chen Chen; Xinwei Zhao; Matthew C. Stamm,IEEE Transactions on Information Forensics and Security,Multimedia,Unspecified,No,Evasion,Mislead forensic source attribution by falsifying an image’s camera-model traces (targeted misattribution),Deep-learning camera model identification classifiers (CNN-based),Implemented+Evaluated,GAN-inspired generator trained to modify images so camera-model CNNs misclassify them as a chosen target camera model; supports white-box (uses classifier directly) and black-box (uses substitute network) attacks with high targeted success rates.,Camera-model forensic traces (including demosaicing/CFA-related traces and CNN-learned camera fingerprints),Journal volume shows 2025; manuscript history indicates earlier workflow dates; not mobile-focused.,No,46
P002,BDC-GAN: Bidirectional Conversion Between Computer-Generated and Natural Facial Images for Anti-Forensics,2022,Fei Peng; Liping Yin; Min Long,"IEEE Transactions on Circuits and Systems for Video Technology (Vol. 32, No. 10)",Multimedia,Unspecified,No,Generation,Degrade forensic discrimination between computer-generated (CG) and natural (NI) facial images by converting images across domains while preserving facial content,"CG vs NI facial-image forensic detectors (traditional feature-based and deep-learning-based, 9 methods)",Implemented+Evaluated,"BDC-GAN encodes content and sensor-pattern-noise separately, then swaps/interchanges noise between CG and NI to perform bidirectional CG↔NI conversion; uses multi-scale discriminators and combined noise/content/reconstruction/adversarial losses; evaluated against 9 forensic methods showing strong deception ability.",Sensor pattern noise / PRNU-like cues; texture/smoothness cues; deep-learning forensic features,Threat model targets NI/CG source detectors (not deepfake detection). Uses PES/FIFA/CelebA-based datasets; focuses on visual quality + detector bypass.,No,30
AAF-001,Evaluating the Efficacy of RGB-D Cameras for Surveillance,Not reported,"Raghuraman, Bahirat, Prabhakaran",IEEE,Multimedia,Windows;Unspecified,No,Generation,Create forged video streams showing individuals performing activities they did not do,RGB-D surveillance systems; depth-based re-identification systems,Implemented+Evaluated,"Real-time framework using depth segmentation, skeleton-based mesh deformation (random forest for pose), and 3D rendering to generate Type I (human insertion) and Type II (behavior manipulation) forgeries",Inter-frame noise patterns; edge artifacts in color images; texture stretching; occlusion anomalies,ML component limited to skeleton identification via random forest; primary techniques are traditional CV/graphics; user study showed 76% undetectable at low resolution,Yes,15
P001,SafePaint: Anti-forensic Image Inpainting with Domain Adaptation,2024,Dunyun Chen; Xin Liao; Xiaoshuai Wu; Shiwei Chen,MM '24: Proceedings of the 32nd ACM International Conference on Multimedia (ACM),Multimedia,Unspecified,No,Generation,Modify visual evidence (inpaint/remove/replace content) while minimizing forensic tampering traces.,Image inpainting / forgery detectors and their learned tampering-trace signals.,Implemented+Evaluated,Two-stage deep inpainting (content completion + region-wise optimization) trained end-to-end; uses domain adaptation (domain pattern extractor + domain distance loss) and region-wise separated attention (RWSA) to harmonize inpainted foreground with original background.,Tampering traces/heatmaps; manipulation masks; distribution mismatch between generated and original regions.,Paper explicitly proposes an end-to-end framework for anti-forensic image inpainting using domain adaptation and an RWSA module.,No,1
P001,SafePaint: Anti-forensic Image Inpainting with Domain Adaptation,2024,Dunyun Chen; Xin Liao; Xiaoshuai Wu; Shiwei Chen,MM '24: Proceedings of the 32nd ACM International Conference on Multimedia (ACM),Multimedia,Unspecified,No,Evasion,Evade forensic detection by reducing detectable distribution inconsistencies between inpainted and pristine regions.,"Pre-trained forensic detectors (PSCC-Net, TruFor, IID-Net) used to localize/score manipulations.",Implemented+Evaluated,Trains inpainting with anti-forensic objective: domain adaptation narrows foreground/background distribution gap; evaluation uses detector metrics where lower AUC/F1/ACC indicate better detection evasion.,Detector AUC/F1/ACC; detector heatmaps and predicted manipulation masks.,"Anti-forensic analysis evaluates evasion against PSCC-Net, TruFor, and IID-Net; SafePaint reports substantially lower detection metrics than prior inpainting methods.",No,1
P001,Anti-forensics of fake stereo audio using generative adversarial network,2022,Tianyun Liu; Diqun Yan; Nan Yan; Gang Chen,"Multimedia Tools and Applications (Springer Nature), Vol. 81, 17155–17167 (Published online: 5 March 2022)",Multimedia,Unspecified,No,Generation,Create high-quality fake stereo audio from mono audio by generating a synthetic “other channel”.,Stereo-faking forensics context (fake stereo audio detection) and downstream authenticity assessment.,Implemented+Evaluated,"GAN framework generates a new channel x' from mono x (SEGAN-inspired encoder–decoder with skip connections). Combine x and x' to form a fake stereo pair; trained on large music/film datasets (44.1 kHz, 16-bit WAV) to preserve perceptual quality.","Stereo channel relationship/correlation; waveform structure; perceptual quality measures (ABX, SSNR); distribution of generated vs real right-channel audio.",Uses skip connections to reduce information loss and improve perceived quality; evaluated with ABX (~51% average) and SSNR (~7.77).,No,28
P001,Anti-forensics of fake stereo audio using generative adversarial network,2022,Tianyun Liu; Diqun Yan; Nan Yan; Gang Chen,"Multimedia Tools and Applications (Springer Nature), Vol. 81, 17155–17167 (Published online: 5 March 2022)",Multimedia,Unspecified,No,Evasion,Deceive fake-stereo forensic detectors so the forged stereo is classified as “real stereo”.,Fake stereo audio detector in prior work: MFCC features + SVM classifier (models for MUSIC and FILM).,Implemented+Evaluated,Generated fake stereo samples are used as anti-forensic attacks against stereo-faking detectors. Reports large drops in detector accuracy and large increases in false acceptance; also demonstrates cross-database attacks (music↔film) retaining high attack effectiveness.,Detector decision metrics (ACC/FAR); MFCC-based feature space; left/right channel consistency learned by the detector.,Key reported effect (Table 1): MUSIC ACC ~99.25%→30.11% and FAR ~0.08%→69.89%; FILM ACC ~99.99%→1.70% and FAR ~0.02%→98.30%. Cross-database (Table 2) reduces ACC to ~5–6% with FAR ~94%.,No,28
P001,Synthesizing Black-Box Anti-Forensics DeepFakes with High Visual Quality,2024,Bing Fan; Shu Hu; Feng Ding,"ICASSP 2024 (IEEE), DOI: 10.1109/ICASSP48485.2024.10447611",Multimedia,Unspecified,No,Evasion,Evade DeepFake detectors while producing visually pleasing (sharpened) DeepFake images using adversarial sharpening masks.,"CNN-based DeepFake detectors (ResNet-50, DenseNet-121, EfficientNet, MobileNet, ShuffleNet, ConvNeXt, EfficientNet-SBIs) evaluated across Celeb-DF, DeeperForensics, and FaceForensics++ benchmarks.",Implemented+Evaluated,Two-stage GAN framework: (1) Forensics Disruption Network (FDN) learns an adversarial mask m such that synthesized images Is = If + m are highly undetectable; (2) Visual Enhancement Network (VEN) with MobileViT blocks refines to a sharpening adversarial mask m′ so outputs resemble naturally sharpened images while retaining high black-box anti-forensics performance. Compared against prior anti-forensics methods and tested against multiple pre-trained detectors.,"Adversarial masks (m, m′); detector prediction precision/accuracy; detector heatmaps; PSNR/SSIM; face-detection recognizability.","Reported results show strong detector disruption (e.g., prediction precision on fake images drops to low single/teens percentages for ‘ours’ across detectors/datasets) while maintaining high visual quality with sharpening (PSNR/SSIM competitive or improved).",No,28
,"```json
{
  ""title"": ""Making Generated Images Hard To Spot: A Transferable Attack On Synthetic Image Detectors""
}
```",,,,Multimedia,Unspecified,No,Generation,,,Implemented+Evaluated,,,,,
P001,Making DeepFakes More Spurious: Evading Deep Face Forgery Detection via Trace Removal Attack,2023,Chi Liu; Huajie Chen; Tianqing Zhu; Jun Zhang; Wanlei Zhou,"IEEE Transactions on Dependable and Secure Computing (TDSC), Vol. 20, No. 6 (Nov/Dec 2023), DOI: 10.1109/TDSC.2023.3241604",Multimedia,Unspecified,No,Trace_suppression,Bypass arbitrary/unknown DeepFake detectors by removing universal counterfeiting traces while preserving visual quality.,"DeepFake detectors (spatial, frequency, fingerprint, and ensemble detectors), including defended detectors via data augmentation.",Implemented+Evaluated,"Proposes a detector-agnostic 'trace removal' anti-forensics attack. Identifies three intrinsic DeepFake traces (spatial anomalies, spectral disparities, noise fingerprints) and trains an adversarial-learning Trace Removal Network (TR-Net) with one generator and multiple discriminators (one per trace domain) to remove all traces simultaneously. Uses semantically-closest real/fake pairs; optimizes adversarial loss plus perceptual similarity and PSD regularization. Evaluated against multiple detectors and heterogeneous defense/knowledge scenarios, showing strong cross-detector transferability with negligible visual degradation.","Spatial anomalies; spectral disparities (DFT amplitude/phase, PSD); noise/GAN fingerprints (SRM residuals, NCC correlations); detector accuracy; PSNR/SSIM","Key results reported: on undefended detectors, average detection accuracy drops from ~92% (clean) to ~23% (TR-Net) while achieving high visual quality (PSNR ~35.16 dB, SSIM ~0.988). Attack requires zero knowledge of the target detector and operates without querying it.",No,67
,"```json
{
  ""title"": ""Black-Box Attack against GAN-Generated Image Detector with Contrastive Perturbation""
}
```",,,,Multimedia,Unspecified,No,Trace_suppression,,,Implemented+Evaluated,,,,,
P001,Attacking Image Splicing Detection and Localization Algorithms Using Synthetic Traces,2024,Shengbang Fang; Matthew C. Stamm,"IEEE Transactions on Information Forensics and Security (TIFS), Vol. 19 (2024), DOI: 10.1109/TIFS.2023.3346312",Multimedia,Unspecified,No,Evasion,Evade image splicing detection and localization by synthesizing self-consistent forensic traces so spliced regions appear authentic; also enables misinformation by making authentic regions appear fake under forensic analysis.,"Splicing detection/localization algorithms based on Siamese networks, including EXIF-Net, Noiseprint, and Forensic Similarity Graphs; trained against Siamese networks (FSG and EXIF-Net) with transfer to Noiseprint.",Implemented+Evaluated,"Proposes a GAN-based anti-forensic attack that synthesizes homogeneous, authentic-looking forensic traces across a full-size image (not patch-by-patch adversarial noise). Uses a two-phase training strategy: Phase 1 pre-trains a fully convolutional generator to fool a camera-model classifier (MISLNet) to learn transferable forensic embeddings; Phase 2 adversarially trains the generator against one or more forensic Siamese networks using an ensemble Siamese loss so that attacked patches are judged 'same-source'. The trained generator is reused to attack any spliced image by a single forward pass, maintaining high visual quality while degrading splicing detection (mAP/AUC) and localization (F1/MCC).",Synthetic forensic traces/fingerprints (camera-model / EXIF self-consistency / Noiseprint-like traces); Siamese similarity scores; detection mAP (AUC); localization F1 and MCC; image quality PSNR and SSIM,"Key results reported: (i) Patch-level attacks achieve very high successful attack rates on Siamese networks (e.g., ~99.9% on FSG and ~97% on EXIF-Net) with high quality (mean PSNR ≈41+ and SSIM ≈0.975+). (ii) Splicing detection performance is reduced to near-random or worse (mAP ≤0.5 on Columbia and often <0.10 on DSO-1/Korus under best training). (iii) Localization F1/MCC drop substantially and the attack transfers to Noiseprint despite not training against it. Attacked images retain high quality (PSNR >40, SSIM >0.96).",No,10
,Exploring Adversarial Fake Images on Face Manifold,2021,Dongze Li; Wei Wang; Hongxing Fan; Jing Dong,CVPR 2021 (IEEE/CVF Conference on Computer Vision and Pattern Recognition),Multimedia,Unspecified,No,Evasion,Generate high-visual-quality GAN fake faces that bypass deepfake/fake-image forensic detectors without adding obvious pixel-space adversarial noise.,Image forensic (fake-image) detectors based on Xception and EfficientNet (and their ensembles); includes transfer to other forensic models in black-box settings.,Implemented+Evaluated,"Searches adversarial points on the StyleGAN face manifold by iteratively applying gradient-based updates in the generator’s latent space (latent vector z and/or per-layer noise inputs n1…n8). Each step follows the loss gradient of the target forensic detector(s), producing an adversarial latent/noise configuration that generates a fake image classified as 'real'. The approach supports single-model and ensemble attacks, and evaluates white-box and black-box transferability. Reports detector accuracy dropping from >90% on clean StyleGAN images to ~0–1% on attacked images, while maintaining strong perceptual quality compared to norm-bounded FGSM/PGD baselines.","Adversarial latent vectors and per-layer noise inputs; facial texture/attribute changes; detector accuracy/ASR; ensemble-loss/logit strategies; image-quality metrics (MSE, PSNR, SSIM, LPIPS) and user-study preferences.",Key reported results: clean accuracy ~97% (EfficientNet) / ~93% (Xception) drops to ~0% after the proposed latent/noise search; ensemble strategies also achieve near-zero accuracy. Visual quality is emphasized (LPIPS + user study outperform PGD/FGSM baselines).,No,71
,Bibliography of digital image anti-forensics and anti-anti-forensics techniques,2019,Muhammad Ali Qureshi; El-Sayed M El-Alfy,"IET Image Processing (Review Article), Vol. 13, Iss. 11, pp. 1811–1823, 2019; doi:10.1049/iet-ipr.2018.6587",Multimedia,Unspecified,No,Evasion,Survey and categorize image anti-forensics methods (including deep learning / GAN-based approaches) that can hide or forge forensic traces to mislead image manipulation detectors and attribution methods.,"Digital image forensic detectors and attribution methods (e.g., contrast enhancement, median filtering, chromatic aberration, CFA/demosaicing traces, PRNU/camera identification, resampling, JPEG compression history).",Conceptual-only,"This paper is a systematic review/bibliography (not a new attack). It surveys anti-forensics techniques (AFTs) and counter anti-forensics (AAFTs), grouping methods by the forensic trace targeted. It explicitly notes recent AI-driven directions within the surveyed literature, including GAN-based attacks to fool CNN-based camera model identification (e.g., MISLGAN-style camera model falsification), GAN-based JPEG compression anti-forensics that learn to conceal compression traces, and adversarial-network-based median filtering anti-forensics/restoration. The paper synthesizes trends, venues, and provides taxonomic groupings to help understand how attackers can evade forensic detection by generating or suppressing traces.","Forensic traces discussed include histogram/CE peak-gap artifacts, median filtering residuals, lateral chromatic aberration inconsistencies, CFA/demosaicing periodic correlations, PRNU sensor noise patterns, resampling periodicities, and JPEG DCT quantization/blocking artifacts. AI-driven anti-forensics referenced in the survey operate by learning to modify images so these traces look consistent or are suppressed while preserving visual quality.","AAF relevance: The paper itself is a survey, but it cites multiple AI-driven anti-forensics works (GAN/adversarial networks) used by an adversary to evade detectors or suppress/forge traces (e.g., GAN-based camera model falsification; GAN-based JPEG trace concealment; adversarial-network-based median filtering anti-forensics). Treat as BACKGROUND/DISCUSSION, not an implemented AAF contribution.",No,36
AAF-002,Anti-Forensics for Face Swapping Videos via Adversarial Training,2022,"Ding, Zhu, Li, Zhang, Atrey, Lyu",IEEE Transactions on Multimedia,Multimedia,Unspecified,No,Evasion,Evade DeepFake forensic detectors by embedding adversarial perturbations into face-swapped videos while preserving visual quality,XceptionNet; ResNet-50; DenseNet; FWA (Face Warping Artifacts) detector,Implemented+Evaluated,Novel GAN architecture with 3 generators (G1-G3) and 6 discriminators (D1-D6) using U-Net based encoder-decoder; adversarial training embeds perturbation noise into DeepFake frames; custom loss function with L1/L2 penalties prevents inter-generator cheating,Adversarial perturbations invisible to human eye; no visual artifacts in processed faces; Mask-SSIM similarity scores; VGG16-based face quality evaluator,"Tested on FF++, Celeb-DF, DFDC datasets; XceptionNet detection dropped from 98.95% to 12.86% (FF++); maintains high visual quality (89.46% score vs 50.13% for competing method)",No,164
P001,CGR-GAN: CG Facial Image Regeneration for Antiforensics Based on Generative Adversarial Network,2020,Fei Peng; Li-Ping Yin; Le-Bing Zhang; Min Long,"IEEE Transactions on Multimedia, Vol. 22, No. 10 (Oct 2020), DOI: 10.1109/TMM.2019.2959443",Multimedia,Unspecified,No,Evasion,Regenerate computer-generated (CG) facial images so they appear natural and evade detectors that distinguish CG from natural images (NI).,"CG-vs-NI forensic detectors, including traditional feature-based detectors and deep learning-based CG detectors; evaluated as black-box attacks.",Implemented+Evaluated,"Proposes CGR-GAN, a GAN-based anti-forensics scheme that learns a one-way mapping from CG facial images to an NI-like distribution while preserving the original face profile. The generator uses a deep U-Net with skip connections; the discriminator uses a PatchGAN-style fully convolutional network trained with WGAN-GP to approximate Wasserstein distance. Training optimizes a weighted sum of (i) content loss using VGG-19 high-level features (to preserve facial profile), (ii) style loss using multi-layer VGG-19 features (to introduce NI statistics), (iii) adversarial loss, and (iv) total-variation regularization to smooth artifacts. The resulting regenerated images (CGR) reduce CG detectors’ accuracy/detection rate across multiple detectors and datasets, striking a balance between visual quality and deception ability.","Image-level forensic cues used by CG detectors (texture/color/style statistics), VGG-19 feature representations for content/style losses, PatchGAN/WGAN-GP discriminator scores, and evaluation metrics Acc (overall accuracy) and Det (CG detection rate). Notes that detectors relying on sensor pattern noise are harder to fool when the attack only modifies style.","The paper is explicitly framed as 'anti-forensics' against CG detectors. Experiments report substantial reductions in CG detection rate for multiple feature-based and CNN-based CG detectors (often >60% of regenerated CG can evade), but limited impact on a detector that uses sensor pattern noise.",No,38
P001,Towards Multi-Operation Image Anti-Forensics with Generative Adversarial Networks,2020,Jianyuan Wu,"Computers & Security (Elsevier), 2020 (Journal Pre-proof), Article 102083, DOI: 10.1016/j.cose.2020.102083",Multimedia,Unspecified,No,Trace_suppression,"Conceal/eliminate forensic traces left by one or multiple image processing/manipulation operations (e.g., JPEG compression + median filtering chains) so that state-of-the-art forensic detectors misclassify manipulated images as original.","Image forensic detectors for manipulation chains, including CNN-based detectors (e.g., Bayar & Stamm-style constrained CNN; Chen et al. densely connected CNN) and an SVM-based counter anti-forensics method using residual/autoregressive features.",Implemented+Evaluated,"Proposes a GAN-based anti-forensics framework to remove traces of multiple successive operations. Trains (i) seven single-operation generators (for MF, JPEG, gamma correction, unsharp masking, AWGN, S-mapping, Gaussian blur) and extends them to multi-operation settings via two strategies: (Strategy I) sequentially apply the relevant single-operation generators to erase traces in a chain; (Strategy II) retrain the GAN on multi-operation images to learn a dedicated generator for the chain. Generator is SRGAN-inspired with residual blocks; discriminator ingests the image plus concatenated outputs of several 5×5 high-pass filters to emphasize residual artifacts. Generator loss combines pixel-wise loss, VGG-19 perceptual loss, high-frequency residual loss, and adversarial loss. Evaluations on BossBase/BOWS2 show detection rates for CNN-based forensics reduced toward chance (~50–60% accuracy depending on chain), while some SVM/residual-feature detectors remain more robust.","Targeted forensic traces include JPEG quantization/blocking artifacts (DCT/spatial), median-filter streaking artifacts, contrast-enhancement peak/gap histogram artifacts (discussed), unsharp masking overshoot artifacts, and residual-domain statistics. Uses high-pass filtered residual stacks in the discriminator; reports PSNR/SSIM as quality metrics and detector accuracies for CNN/SVM forensics.",Explicitly positions the adversary as a 'forensic attacker' using GANs to erase manipulation traces (single- and multi-operation). Two-strategy comparison: retraining on multi-operation images improves visual quality (PSNR/SSIM) and is competitive on evasion; SVM-based counter-anti-forensics based on residual statistics can still detect many multi-operation cases at higher accuracy.,No,24
P001,Perception matters: Exploring imperceptible and transferable anti-forensics for GAN-generated fake face imagery detection,2021,Yongwei Wang; Xin Ding; Yixin Yang; Li Ding; Rabab Ward; Z. Jane Wang,"Pattern Recognition Letters, Vol. 146 (2021) 15–22, DOI: 10.1016/j.patrec.2021.03.009",Multimedia,Unspecified,No,Evasion,"Bypass GAN-generated fake-face image detectors using imperceptible, transferable adversarial perturbations (black-box transfer setting), while preserving facial visual quality.",Fake-face imagery forensic detectors: six deep-learning detectors (m1–m6) and a non-deep-learning detector (NDL) (targeted via transfer-based black-box attacks).,Implemented+Evaluated,"Formulates fake-face anti-forensics as transfer-based adversarial attacks under perceptual constraints. Shows that standard RGB-domain transfer attacks concentrate perturbation energy in luminance (Y), causing visible artifacts on smooth face/background regions. Proposes a perception-aware iterative attack in YCbCr: directly optimize perturbation ζ in YCbCr with channel-wise ℓ∞ budgets (smaller for Y, larger for Cb/Cr), using momentum-iterative gradient updates, projection, and inverse transform back to RGB. Evaluates against multiple forensic models on StyleGAN and StyleGAN2 datasets, improving both transferability (attack success rate) and visual quality (NIQE/LPIPS/FSIMc) compared to FGSM/MIM baselines.","Adversarial perturbations in YCbCr (channel-wise budgets); perturbation residue histograms; detector true positive/negative rates (TPR/TNR); attack success rate (ASR); transfer matrices across models; image-quality metrics NIQE, LPIPS, FSIMc; robustness checks under JPEG compression.","Paper explicitly frames the method as 'anti-forensics' for GAN fake-face detection. Reported highlights: with imperceptibility constraints, the proposed YCbCr allocation yields ~30% higher transferability than baseline transfer attacks (abstract). In Table 2, average ASR on fake images improves to 79.2% (StyleGAN) and 73.5% (StyleGAN2) versus FGSM/MIM baselines, while also improving FSIMc.",No,33
AAF-003,End-to-End Anti-Forensics Network of Single and Double JPEG Detection,2021,"Kim, Ahn, Lee",IEEE Access,Multimedia,Unspecified,No,Evasion,Evade JPEG compression detectors and Double JPEG (DJPEG) detectors to hide evidence of image manipulation/recompression history,"6 JPEG detectors (calibration, block artifact, gradient, quantization estimation, total variation); CNN-based DJPEG detectors; SRNet steganalysis detector",Implemented+Evaluated,"CNN-based method using EDSR network architecture with DCT constraints; three custom loss functions: reconstruction loss (MSE), histogram loss (DCT distribution matching), and deblocking loss (TV minimization); soft DCT coefficient clamping with trainable parameter",DCT histogram distribution; block boundary artifacts; calibration features; minimum decision error rates approaching 0.5 (random guessing),Tested on BossBase 1.01 and BOWS2 datasets; achieves ~0.43-0.46 mean minimum decision error vs JPEG detectors; outperforms prior anti-forensics (Fan et al.) in visual quality while maintaining undetectability; generalizes across QF values and resolutions,No,10
P001,Generating Higher-Quality Anti-Forensics DeepFakes with Adversarial Sharpening Mask,2025,Bing Fan; Feng Ding; Guopu Zhu; Jiwu Huang; Sam Kwong; Pradeep Atrey; Siwei Lyu,"ACM Transactions on Multimedia Computing, Communications and Applications (TOMM), Vol. 21, Issue 6, Article 180 (July 2025). DOI: 10.1145/3729233",Multimedia,Unspecified,No,Evasion,"Produce DeepFake frames that evade state-of-the-art DeepFake detectors via black-box anti-forensics, while maintaining (and even enhancing) visual quality so the outputs look like plausible sharpened images to humans.","DeepFake forensic detectors (binary real vs fake classifiers), including ResNet, DenseNet, EfficientNet, ShuffleNet, MobileNet, ConvNeXt, and specialized DeepFake detectors (Efficient-SBIs; Chen et al.).",Implemented+Evaluated,"Proposes a two-stage framework that generates an 'adversarial sharpening mask' to disguise DeepFakes as naturally sharpened pristine images. Stage 1 trains a Forensics Disruption Network (FDN) (U-Net generator + CNN discriminator) to inject an anti-forensics mask m into DeepFake frames to cross detector decision boundaries (undetectability), using sharpened pristine images (via Unsharp Masking/USM) as the target distribution. Stage 2 trains a Visual Enhancement Network (VEN) with a second generator that refines m into an adversarial sharpening mask m′ that restores details and yields pleasant sharpening effects; VEN introduces MobileViT2 blocks to add global attention and reduce complexity, and uses a parameter-frozen strategy where the FDN generator is frozen during VEN training. Evaluated across multiple DeepFake datasets (Celeb-DF, FaceForensics++, DeeperForensics, WildDeepFake) and multiple detectors, showing reduced detector precision/accuracy on fake frames while improving image quality metrics (e.g., PSNR/SSIM/FID) relative to prior anti-forensics baselines.","Adversarial masks (m, m′) added to DeepFake frames; USM-sharpened reference images; detector outputs/precision (fake-frame prediction precision) across detectors; quality metrics PSNR, SSIM, FID; face-detection/recognizability checks; ablations for MobileViT2 blocks and freezing strategy.","Paper explicitly studies 'DeepFake anti-forensics' and aims to disrupt detectors in a black-box setting while keeping outputs visually convincing. Key idea is to frame perturbations as plausible sharpening artifacts (USM-guided), since USM alone does not fool detectors, but USM-guided adversarial masks can. Reports strong undetectability improvements vs multiple prior methods and improved visual quality (Table 5–6). Code link provided in the paper.",No,